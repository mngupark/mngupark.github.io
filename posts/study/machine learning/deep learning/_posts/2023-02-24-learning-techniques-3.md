---
layout: post
title: Learning-Techniques-3
category: deep learning
post-series: Deep learning from scratch
post-order: 18
---

μ΄μ „ [post](https://gyuhub.github.io/posts/study/machine%20learning/deep%20learning/learning-techniques-2)μ—μ„λ” **κ°€μ¤‘μΉ μ΄κΉƒκ°’**κ³Ό **λ°°μΉ μ •κ·ν™”**μ— λ€ν•΄μ„ λ°°μ› μµλ‹λ‹¤. μ΄λ² postμ—μ„λ” μ‹ κ²½λ§ ν•™μµμ **μ¤λ²„ν”Όν…**μ„ μ–µμ ν•λ” κΈ°μ μ— λ€ν•΄μ„ μ•μ•„λ³΄κ² μµλ‹λ‹¤.

---

# μ¤λ²„ν”Όν…

κΈ°κ³„ν•™μµμ—μ„λ” **μ¤λ²„ν”Όν…**μ΄ λ¬Έμ κ°€ λλ” μΌμ΄ λ§μµλ‹λ‹¤. μ¤λ²„ν”Όν…μ΄λ€ μ‹ κ²½λ§μ΄ **ν›λ ¨ λ°μ΄ν„°**μ—λ§ μ§€λ‚μΉκ² μ μ‘λμ–΄ κ·Έ μ™Έμ λ°μ΄ν„°μ—λ” μ λ€λ΅ λ€μ‘ν•μ§€ λ»ν•λ” μƒνƒλ¥Ό λ§ν•©λ‹λ‹¤. κΈ°κ³„ν•™μµμ€ λ²”μ©μ μΈ μ„±λ¥μ„ μ§€ν–¥ν•©λ‹λ‹¤. ν›λ ¨ λ°μ΄ν„°μ—λ” ν¬ν•¨λμ§€ μ•λ”, **μ•„μ§ λ³΄μ§€ λ»ν• λ°μ΄ν„°**κ°€ μ£Όμ–΄μ Έλ„ λ°”λ¥΄κ² μ‹λ³„ν•΄λ‚΄λ” λ¨λΈμ΄ λ°”λμ§ν•©λ‹λ‹¤. λ³µμ΅ν•κ³  ν‘ν„λ ¥μ΄ λ†’μ€ λ¨λΈμ„ λ§λ“¤ μλ” μμ§€λ§, κ·Έλ§νΌ μ¤λ²„ν”Όν…μ„ μ–µμ ν•λ” κΈ°μ μ΄ μ¤‘μ”ν•΄μ§€λ” κ²ƒμ…λ‹λ‹¤.

μ¤λ²„ν”Όν…μ€ μ£Όλ΅ λ‹¤μμ λ‘ κ²½μ°μ— μΌμ–΄λ‚©λ‹λ‹¤.
* λ§¤κ°λ³€μκ°€ **λ§κ³ ** ν‘ν„λ ¥μ΄ **λ†’μ€** λ¨λΈ
* ν›λ ¨ λ°μ΄ν„°κ°€ **μ μ€** κ²½μ°

μ„ λ‘ μ΅°κ±΄μ„ μ¶©μ΅±ν•λ©΄ μ–΄λ–¤ μΌμ΄ λ°μƒν• κΉμ”? μ‹¤μ λ΅ λ‘ μ΅°κ±΄μ„ μ¶©μ΅±ν•μ—¬ μ¤λ²„ν”Όν…μ„ **μΌλ¶€λ¬** μΌμΌμΌλ³΄κ² μµλ‹λ‹¤. μ›λ 60,000κ°μ ν›λ ¨ λ°μ΄ν„°λ΅ μ΄λ£¨μ–΄μ§„ MNIST λ°μ΄ν„°μ…‹μ—μ„ **500κ°**λ§ μ‚¬μ©ν•΄μ„ ν›λ ¨ λ°μ΄ν„°λ¥Ό μ¤„μ΄κ³ , **7μΈµ** λ„¤νΈμ›ν¬λ¥Ό μ‚¬μ©ν•΄μ„ λ„¤νΈμ›ν¬μ λ³µμ΅μ„±μ„ λ†’μ΄κ² μµλ‹λ‹¤. κ° μΈµμ λ‰΄λ°μ€ 100κ°, ν™μ„±ν™” ν•¨μλ” ReLUλ¥Ό μ‚¬μ©ν•κ² μµλ‹λ‹¤. κ²°κ³Όλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/learning_techniques_28.png"
         title="Comparison of accuracy between train and test dataset when overfitting occurred"
         alt="Image of comparison of accuracy between train and test dataset when overfitting occurred"
         class="img_center"
         style="width: 60%"/>
    <figcaption>μ¤λ²„ν”Όν…μ΄ λ°μƒν•λ” μ΅°κ±΄μ„ μ¶©μ΅±ν–μ„λ• ν›λ ¨ λ°μ΄ν„°μ™€ μ‹ν— λ°μ΄ν„°μ μ •ν™•λ„ λΉ„κµ</figcaption>
</figure>

[Fig. 1.]μ„ λ³΄μ‹λ©΄ ν›λ ¨ λ°μ΄ν„°μ κ²½μ° μ•½ 75 λ°ν­μ„ μ§€λ‚λ” λ¬΄λ µλ¶€ν„° κ±°μ 100%μ μ •ν™•λ„λ¥Ό κΈ°λ΅ν–μµλ‹λ‹¤. λ°λ©΄μ— μ‹ν— λ°μ΄ν„°μ κ²½μ°μ—λ” μ‹κ°„μ΄ νλ¬λ„ 80% μ΄μƒμ μ •ν™•λ„λ” λ„μ–΄μ„μ§€ λ»ν•λ” λ¨μµμ„ λ³΄μ…λ‹λ‹¤. μ΄μ²λΌ **ν›λ ¨ λ°μ΄ν„°**μ—λ§ μ μ‘ν•΄λ²„λ¦¬λ” κ²ƒμ΄ λ°”λ΅ **μ¤λ²„ν”Όν…**μ…λ‹λ‹¤.

## κ°€μ¤‘μΉ κ°μ†

μ¤λ²„ν”Όν…μ„ μ–µμ ν•κΈ° μ„ν• λ°©λ²•μΌλ΅ μλ΅λ¶€ν„° λ§μ΄ μ΄μ©ν•΄μ¨ **κ°€μ¤‘μΉ κ°μ†**(weight decay)λΌλ” κ²ƒμ΄ μμµλ‹λ‹¤. μ΄λ” ν•™μµ κ³Όμ •μ—μ„ **ν°** κ°€μ¤‘μΉμ— λ€ν•΄μ„λ” κ·Έμ— μƒμ‘ν•λ” **ν° νλ„ν‹°**λ¥Ό λ¶€κ³Όν•μ—¬ μ¤λ²„ν”Όν…μ„ μ–µμ ν•λ” λ°©λ²•μ…λ‹λ‹¤. μ›λ μ¤λ²„ν”Όν…μ€ κ°€μ¤‘μΉ λ§¤κ°λ³€μμ *κ°’μ΄ μ»¤μ„* λ°μƒν•λ” κ²½μ°κ°€ λ§κΈ° λ•λ¬Έμ…λ‹λ‹¤.

μ‹ κ²½λ§ ν•™μµμ λ©μ μ€ <ins>μ†μ‹¤ ν•¨μμ κ°’μ„ μ¤„μ΄λ” κ²ƒ</ins>μ…λ‹λ‹¤. μ΄λ•, μλ¥Ό λ“¤μ–΄ κ°€μ¤‘μΉμ **μ κ³± λ…Έλ¦„**(L2 λ…Έλ¦„, L2 norm)μ„ μ†μ‹¤ ν•¨μμ— λ”ν•©λ‹λ‹¤. κ·Έλ ‡λ‹¤λ©΄ κ°€μ¤‘μΉκ°€ μ»¤μ§€λ” κ²ƒμ„ μ–µμ ν•  μ μκ² μ£ . κ°€μ¤‘μΉλ¥Ό $\boldsymbol{W}$λΌ ν•λ©΄ L2 λ…Έλ¦„μ— λ”°λ¥Έ κ°€μ¤‘μΉ κ°μ†λ” $\frac{1}{2}\lambda\boldsymbol{W}^2$μ΄ λκ³ , μ΄ $\frac{1}{2}\lambda\boldsymbol{W}^2$μ„ μ†μ‹¤ ν•¨μμ— λ”ν•©λ‹λ‹¤. μ—¬κΈ°μ—μ„ $\lambda$λ” μ •κ·ν™”μ μ„ΈκΈ°λ¥Ό μ΅°μ ν•λ” **ν•μ΄νΌνλΌλ―Έν„°**μ…λ‹λ‹¤. $\lambda$λ¥Ό **ν¬κ²** μ„¤μ •ν• μλ΅ **ν° κ°€μ¤‘μΉ**μ— λ€ν• νλ„ν‹°κ°€ μ»¤μ§‘λ‹λ‹¤. $\frac{1}{2}\lambda\boldsymbol{W}^2$μ—μ„ $\frac{1}{2}$μ€ $\frac{1}{2}\lambda\boldsymbol{W}^2$μ λ―Έλ¶„ κ²°κ³ΌμΈ $\lambda\boldsymbol{W}$λ¥Ό μ΅°μ •ν•λ” μ—­ν• μ μƒμμ…λ‹λ‹¤.

κ°€μ¤‘μΉ κ°μ†λ” λ¨λ“  κ°€μ¤‘μΉ κ°κ°μ μ†μ‹¤ ν•¨μμ— $\frac{1}{2}\lambda\boldsymbol{W}^2$μ„ λ”ν•©λ‹λ‹¤. λ”°λΌμ„ κ°€μ¤‘μΉμ κΈ°μΈκΈ°λ¥Ό κµ¬ν•λ” κ³„μ‚°μ—μ„λ” κ·Έλ™μ•μ μ¤μ°¨μ—­μ „νλ²•μ— λ”°λ¥Έ κ²°κ³Όμ— μ •κ·ν™” ν•­μ„ λ―Έλ¶„ν• $\lambda\boldsymbol{W}$λ¥Ό λ”ν•©λ‹λ‹¤.

> π’΅ L2 λ…Έλ¦„μ€ **κ° μ›μ†μ μ κ³±**μ„ λ”ν• κ²ƒμ— ν•΄λ‹Ήν•©λ‹λ‹¤. κ°€μ¤‘μΉ $W=\begin{pmatrix} w_1 & w_2 & \cdots & w_n \end{pmatrix}$ μ΄ μλ‹¤λ©΄, L2 λ…Έλ¦„μ—μ„λ” $\sqrt{w_1^2+w_2^2+\cdots+w_n^2}$μΌλ΅ κ³„μ‚°ν•  μ μμµλ‹λ‹¤. L2 λ…Έλ¦„ μ™Έμ— L1 λ…Έλ¦„κ³Ό L$\infty$ λ…Έλ¦„λ„ μμµλ‹λ‹¤. L1 λ…Έλ¦„μ€ μ λ“κ°’μ ν•©, μ¦‰ $\left \vert w_1 \right \vert+\left \vert w_2 \right \vert+\cdots+\left \vert w_n \right \vert$μ— ν•΄λ‹Ήν•©λ‹λ‹¤. L$\infty$ λ…Έλ¦„μ€ Max λ…Έλ¦„μ΄λΌκ³ λ„ ν•λ©°, κ° μ›μ†μ μ λ“κ°’ μ¤‘ κ°€μ¥ ν° κ²ƒμ— ν•΄λ‹Ήν•©λ‹λ‹¤. μ •κ·ν™” ν•­μΌλ΅ L2 λ…Έλ¦„, L1 λ…Έλ¦„, L$\infty$ λ…Έλ¦„ μ¤‘ μ–΄λ–¤ κ²ƒλ„ μ‚¬μ©ν•  μ μμµλ‹λ‹¤.

κ·Έλ¬λ©΄ κ°€μ¤‘μΉ κ°μ†λ¥Ό ν•λ² μ μ©ν•΄λ³΄κ² μµλ‹λ‹¤. [Fig. 1.]μ—μ„λ” $\lambda=0.1$μ κ°€μ¤‘μΉ κ°μ†λ¥Ό μ μ©ν•©λ‹λ‹¤. κ²°κ³Όλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/learning_techniques_29.png"
         title="Comparison of accuracy between train and test dataset when applied weight decay method"
         alt="Image of comparison of accuracy between train and test dataset when applied weight decay method"
         class="img_center"
         style="width: 60%"/>
    <figcaption>κ°€μ¤‘μΉ κ°μ†λ¥Ό μ μ©ν• ν›λ ¨ λ°μ΄ν„°μ™€ μ‹ν— λ°μ΄ν„°μ μ •ν™•λ„ λΉ„κµ</figcaption>
</figure>

κ°€μ¤‘μΉ κ°μ†λ¥Ό <ins>μ μ©ν•μ§€ μ•μ€</ins> μ‹ κ²½λ§μ <span style="color: blue">ν›λ ¨ λ°μ΄ν„°</span>μ™€ <span style="color: green">μ‹ν— λ°μ΄ν„°</span>μ μ •ν™•λ„ μ°¨μ΄λ³΄λ‹¤ κ°€μ¤‘μΉ κ°μ†λ¥Ό <ins>μ μ©ν•</ins> μ‹ κ²½λ§μ <span style="color: purple">ν›λ ¨ λ°μ΄ν„°</span>μ™€ <span style="color: pink">μ‹ν— λ°μ΄ν„°</span>μ μ •ν™•λ„ μ°¨μ΄κ°€ **λ” μ‘μ€** κ²ƒμ„ ν™•μΈν•  μ μμµλ‹λ‹¤. λ‹¤μ‹ λ§ν•΄ κ°€μ¤‘μΉ κ°μ†λ¥Ό ν†µν•΄μ„ **μ¤λ²„ν”Όν…**μ„ **μ–µμ **ν•λ” κ²ƒμ— μ„±κ³µν–λ‹¤λ” λ§μ…λ‹λ‹¤. ν•μ§€λ§, μ•μ„  κ²½μ°μ™€ λ‹¬λ¦¬ ν›λ ¨ λ°μ΄ν„°μ— λ€ν• μ •ν™•λ„κ°€ **100%**μ— λ„λ‹¬ν•μ§€ λ»ν• μ λ„ μ£Όλ©ν•΄μ•Ό ν•κ² μµλ‹λ‹¤.

---

## λ“λ΅­μ•„μ›ƒ

μ¤λ²„ν”Όν…μ„ μ–µμ ν•λ” λ°©μ‹μΌλ΅ μ†μ‹¤ ν•¨μμ— κ°€μ¤‘μΉμ L2 λ…Έλ¦„μ„ λ”ν•λ” **κ°€μ¤‘μΉ κ°μ†** λ°©λ²•μ„ μ„¤λ…ν–μµλ‹λ‹¤. κ°€μ¤‘μΉ κ°μ†λ” **κµ¬ν„λ„ κ°„λ‹¨ν•κ³ ** μ–΄λ μ •λ„ **μ§€λ‚μΉ ν•™μµ**μ„ μ–µμ ν•λ”λ° λ„μ›€μ΄ λλ‹¤λ” κ²ƒλ„ ν™•μΈν–μµλ‹λ‹¤. ν•μ§€λ§ μ‹ κ²½λ§μ΄ λ³µμ΅ν•΄μ§μλ΅ κ°€μ¤‘μΉ κ°μ†λ§μΌλ΅λ” μ¤λ²„ν”Όν…μ— λ€μ‘ν•κΈ° μ–΄λ ¤μ›μ§‘λ‹λ‹¤. μ΄λ• μ‚¬μ©ν•λ” κΈ°λ²•μ΄ λ°”λ΅ **λ“λ΅­μ•„μ›ƒ**(Dropout)μ…λ‹λ‹¤.

**λ“λ΅­μ•„μ›ƒ**μ€ λ‰΄λ°μ„ **μ„μλ΅ μ‚­μ **ν•λ©΄μ„ ν•™μµν•λ” λ°©λ²•μ…λ‹λ‹¤. ν›λ ¨ λ• **μ€λ‹‰μΈµ**μ λ‰΄λ°μ„ **λ¬΄μ‘μ„λ΅** κ³¨λΌ μ‚­μ ν•©λ‹λ‹¤. μ‚­μ λ λ‰΄λ°μ€ μ•„λ κ·Έλ¦Όκ³Ό κ°™μ΄ μ‹ νΈλ¥Ό μ „λ‹¬ν•μ§€ μ•κ² λ©λ‹λ‹¤. **ν›λ ¨** λ•λ” λ°μ΄ν„°λ¥Ό νλ¦΄ λ•λ§λ‹¤ μ‚­μ ν•  λ‰΄λ°μ„ **λ¬΄μ‘μ„λ΅** μ„ νƒν•κ³ , **μ‹ν—** λ•λ” **λ¨λ“ ** λ‰΄λ°μ— μ‹ νΈλ¥Ό μ „λ‹¬ν•©λ‹λ‹¤. λ‹¨, **μ‹ν— λ•λ”** κ° λ‰΄λ°μ **μ¶λ ¥**μ— ν›λ ¨ λ• **μ‚­μ  μ• ν• λΉ„μ¨**μ„ κ³±ν•μ—¬ μ¶λ ¥ν•©λ‹λ‹¤.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/learning_techniques_30.png"
         title="Comparison of networks within dropout"
         alt="Image of comparison of networks within dropout"
         class="img_center"
         style="width: 60%"/>
    <figcaption>λ“λ΅­μ•„μ›ƒμ κ°λ…. μΌλ°μ μΈ μ‹ κ²½λ§(μΆ)κ³Ό λ“λ΅­μ•„μ›ƒμ„ μ μ©ν• μ‹ κ²½λ§(μ°)</figcaption>
</figure>

κ·Έλ¬λ©΄ λ“λ΅­μ•„μ›ƒμ„ ν•λ² μ μ©ν•΄λ³΄κ² μµλ‹λ‹¤. [Fig. 4.]μ—μ„λ” **0.12**μ λ“λ΅­μ•„μ›ƒ λΉ„μ¨μ„ μ μ©ν•©λ‹λ‹¤. κ²°κ³Όλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/learning_techniques_31.png"
         title="Comparison of accuracy between train and test dataset when applied dropout method"
         alt="Image of comparison of accuracy between train and test dataset when applied dropout method"
         class="img_center"
         style="width: 60%"/>
    <figcaption>λ“λ΅­μ•„μ›ƒμ„ μ μ©ν• ν›λ ¨ λ°μ΄ν„°μ™€ μ‹ν— λ°μ΄ν„°μ μ •ν™•λ„ λΉ„κµ</figcaption>
</figure>

[Fig. 4.]μ™€ κ°™μ΄ λ“λ΅­μ•„μ›ƒμ„ μ μ©ν•λ‹ ν›λ ¨ λ°μ΄ν„°μ™€ μ‹ν— λ°μ΄ν„°μ— λ€ν• μ •ν™•λ„ μ°¨μ΄κ°€ **μ¤„μ—μµλ‹λ‹¤**. λν•, **κ°€μ¤‘μΉ κ°μ†**μ™€ λ§μ°¬κ°€μ§€λ΅ ν›λ ¨ λ°μ΄ν„°μ— λ€ν• μ •ν™•λ„κ°€ **100%**μ— λ„λ‹¬ν•μ§€λ„ μ•κ² λμ—μµλ‹λ‹¤. μ΄μ²λΌ λ“λ΅­μ•„μ›ƒμ„ μ΄μ©ν•λ©΄ ν‘ν„λ ¥μ„ λ†’μ΄λ©΄μ„λ„ μ¤λ²„ν”Όν…μ„ μ–µμ ν•  μ μμµλ‹λ‹¤.

> π“ κΈ°κ³„ν•™μµμ—μ„λ” **μ•™μƒλΈ” ν•™μµ**(ensemble learning)μ„ μ• μ©ν•©λ‹λ‹¤. **μ•™μƒλΈ” ν•™μµ**μ€ κ°λ³„μ μΌλ΅ ν•™μµμ‹ν‚¨ μ—¬λ¬ λ¨λΈμ μ¶λ ¥μ„ ν‰κ· μ„ λ‚΄κ±°λ‚ ν¬ν‘ λ“±μ λ°©λ²•μΌλ΅ μ¶”λ΅ ν•λ” λ°©μ‹μ…λ‹λ‹¤. μ‹ κ²½λ§μ λ§¥λ½μ—μ„ μ–κΈ°ν•λ©΄, κ°€λ Ή κ°™μ€ (νΉμ€ λΉ„μ·ν•) κµ¬μ΅°μ λ„¤νΈμ›ν¬λ¥Ό 5κ° μ¤€λΉ„ν•μ—¬ λ”°λ΅λ”°λ΅ ν•™μµμ‹ν‚¤κ³ , μ‹ν— λ•λ” κ·Έ 5κ°μ μ¶λ ¥μ„ ν‰κ·  λ‚΄μ–΄ λ‹µν•λ” κ²ƒμ…λ‹λ‹¤. μ•™μƒλΈ” ν•™μµμ„ μν–‰ν•λ©΄ μ‹ κ²½λ§μ μ •ν™•λ„κ°€ λ‡% μ •λ„ **κ°μ„ λλ‹¤λ”** κ²ƒμ΄ μ‹¤ν—μ μΌλ΅ μ•λ ¤μ Έ μμµλ‹λ‹¤. 

> μ•™μƒλΈ” ν•™μµκ³Ό **λ“λ΅­μ•„μ›ƒ**μ€ λ°€μ ‘ν•©λ‹λ‹¤. λ“λ΅­μ•„μ›ƒμ΄ ν•™μµ λ• λ‰΄λ°μ„ λ¬΄μ‘μ„λ΅ μ‚­μ ν•λ” ν–‰μ„λ¥Ό <ins>λ§¤λ² λ‹¤λ¥Έ λ¨λΈμ„ ν•™μµμ‹ν‚¤λ” κ²ƒ</ins>μΌλ΅ ν•΄μ„ν•  μ μκΈ° λ•λ¬Έμ…λ‹λ‹¤. κ·Έλ¦¬κ³  μ¶”λ΅  λ•λ” λ‰΄λ ¨μ μ¶λ ¥μ— μ‚­μ ν• λΉ„μ¨μ„ κ³±ν•¨μΌλ΅μ¨ μ•™μƒλΈ” ν•™μµμ—μ„ <ins>μ—¬λ¬ λ¨λΈμ ν‰κ· μ„ λ‚΄λ” κ²ƒ</ins>κ³Ό κ°™μ€ ν¨κ³Όλ¥Ό μ–»λ” κ²ƒμ…λ‹λ‹¤. μ¦‰, λ“λ΅­μ•„μ›ƒμ€ μ•™μƒλΈ” ν•™μµκ³Ό κ°™μ€ ν¨κ³Όλ¥Ό **ν•λ‚μ λ„¤νΈμ›ν¬**λ΅ κµ¬ν„ν–λ‹¤κ³ λ„ μƒκ°ν•  μ μμµλ‹λ‹¤.

---

# μ μ ν• ν•μ΄νΌνλΌλ―Έν„° κ°’ νƒμƒ‰

μ‹ κ²½λ§μ—λ” **ν•μ΄νΌνλΌλ―Έν„°**(hyper parameter)κ°€ λ‹¤μ λ“±μ¥ν•©λ‹λ‹¤. ν•μ΄νΌνλΌλ―Έν„°λ€ μλ¥Ό λ“¤μ–΄ <ins>κ° μΈµμ λ‰΄λ° μ, λ°°μΉμ ν¬κΈ°, λ§¤κ°λ³€μ κ°±μ‹  μ‹μ ν•™μµλ¥ κ³Ό κ°€μ¤‘μΉ κ°μ†</ins> λ“±μ…λ‹λ‹¤. μ΄λ¬ν• ν•μ΄νΌνλΌλ―Έν„°μ κ°’μ„ μ μ ν μ„¤μ •ν•μ§€ μ•μΌλ©΄ λ¨λΈμ μ„±λ¥μ΄ ν¬κ² λ–¨μ–΄μ§€κΈ°λ„ ν•©λ‹λ‹¤. κ·Έλ§νΌ ν•μ΄νΌνλΌλ―Έν„°μ κ°’μ€ λ§¤μ° **μ¤‘μ”**ν•μ§€λ§ κ·Έ κ°’μ„ κ²°μ •ν•κΈ°κΉμ§€λ” μΌλ°μ μΌλ΅ λ§μ€ μ‹ν–‰μ°©μ¤λ¥Ό κ²μµλ‹λ‹¤. λ”°λΌμ„ μ΄λ²μ—λ” μ μ ν• ν•μ΄νΌνλΌλ―Έν„°μ κ°’μ„ μµλ€ν• ν¨μ¨μ μΌλ΅ νƒμƒ‰ν•λ” λ°©λ²•μ— λ€ν•΄μ„ μ•μ•„λ³΄κ² μµλ‹λ‹¤.

## κ²€μ¦ λ°μ΄ν„°

μ§€κΈκΉμ§€λ” μ£Όμ–΄μ§„ λ°μ΄ν„°μ…‹μ„ ν•™μµμ„ μ„ν• **ν›λ ¨ λ°μ΄ν„°**μ™€ λ²”μ© μ„±λ¥ ν‰κ°€λ¥Ό μ„ν• **μ‹ν— λ°μ΄ν„°**λ΅ λ¶„λ¦¬ν•΄μ„ μ΄μ©ν–μµλ‹λ‹¤. μ΄λ¥Ό ν†µν•΄ ν›λ ¨ λ°μ΄ν„°μ—λ§ μ§€λ‚μΉκ² μ μ‘λμ–΄ μμ§€ μ•μ€μ§€(μ¤λ²„ν”Όν…μ΄ λ°μƒν• κ±΄ μ•„λ‹μ§€), κ·Έλ¦¬κ³  λ²”μ© μ„±λ¥μ€ μ–΄λ μ •λ„μΈμ§€ κ°™μ€ κ²ƒμ„ ν‰κ°€ν•  μ μμ—μµλ‹λ‹¤. ν•μ΄νΌνλΌλ―Έν„°κ°€ μ μ ν• μ§€ λ‹¤μ–‘ν• κ°’μΌλ΅ μ„¤μ •ν•κ³  κ²€μ¦ν•  ν…λ°, μ—¬κΈ°μ„ μ£Όμν•  μ μ€ ν•μ΄νΌνλΌλ―Έν„°μ μ„±λ¥μ„ ν‰κ°€ν•  λ•λ” <ins>μ‹ν— λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•΄μ„λ” μ• λλ‹¤λ“  κ²ƒ</ins>μ…λ‹λ‹¤.

κ°™μ€ **μ„±λ¥ ν‰κ°€**μΈλ° ν•μ΄νΌνλΌλ―Έν„°κ°€ λ€μƒμΌ λ•λ” μ‹ν— λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•΄μ„λ” μ• λλ” μ΄μ κ°€ λ¬΄μ—‡μΌκΉμ”? κ·Έκ²ƒμ€ μ‹ν— λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•μ—¬ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•λ©΄ ν•μ΄νΌνλΌλ―Έν„° κ°’μ΄ μ‹ν— λ°μ΄ν„°μ— **μ¤λ²„ν”Όν…**λκΈ° λ•λ¬Έμ…λ‹λ‹¤. κ·Έλ ‡κ² λλ©΄ λ‹¤λ¥Έ λ°μ΄ν„°μ—λ” μ μ‘ν•μ§€ λ»ν•λ‹ λ²”μ© μ„±λ¥μ΄ λ–¨μ–΄μ§€λ” λ¨λΈμ΄ λ μ§€λ„ λ¨λ¦…λ‹λ‹¤. κ·Έλμ„ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μ΅°μ •ν•  λ•λ” **ν•μ΄νΌνλΌλ―Έν„° μ „μ© ν™•μΈ λ°μ΄ν„°**κ°€ ν•„μ”ν•©λ‹λ‹¤. ν•μ΄νΌνλΌλ―Έν„° μ΅°μ •μ© λ°μ΄ν„°λ¥Ό μΌλ°μ μΌλ΅ **κ²€μ¦ λ°μ΄ν„°**(validation data)λΌκ³  λ¶€λ¦…λ‹λ‹¤.

> β¨ λ°μ΄ν„°μ…‹μ„ μ©λ„μ— λ”°λΌμ„ λ¶„λ¥ν•λ©΄ μ•„λμ™€ κ°™μµλ‹λ‹¤.<br>
> * ν›λ ¨ λ°μ΄ν„°: **λ§¤κ°λ³€μ**(κ°€μ¤‘μΉμ™€ νΈν–¥) ν•™μµ
> * κ²€μ¦ λ°μ΄ν„°: **ν•μ΄νΌνλΌλ―Έν„°** μ„±λ¥ ν‰κ°€
> * μ‹ν— λ°μ΄ν„°: μ‹ κ²½λ§μ **λ²”μ© μ„±λ¥** ν‰κ°€

λ°μ΄ν„°μ…‹μ— λ”°λΌμ„λ” ν›λ ¨, κ²€μ¦, μ‹ν— λ°μ΄ν„°λ¥Ό λ―Έλ¦¬ λ¶„λ¦¬ν•΄λ‘” κ²ƒλ„ μμµλ‹λ‹¤. ν•μ§€λ§ κ·Έλ ‡μ§€ μ•μ€ κ²½μ°λ„ μμµλ‹λ‹¤. MNIST λ°μ΄ν„°μ…‹μ€ ν›λ ¨ λ°μ΄ν„°μ™€ μ‹ν— λ°μ΄ν„°λ΅λ§ λ¶„λ¦¬ν•΄λ’€μµλ‹λ‹¤. μ΄λ° κ²½μ°μ—λ” μ‚¬μ©μκ°€ μ§μ ‘ λ°μ΄ν„°λ¥Ό λ¶„λ¦¬ν•΄μ„ μ‚¬μ©ν•λ©΄ λ©λ‹λ‹¤. μ΄μ–΄μ„ κ²€μ¦ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•΄μ„ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μµμ ν™”ν•λ” κΈ°λ²•μ— λ€ν•΄μ„ μ‚΄ν΄λ³΄κ² μµλ‹λ‹¤.

## ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”

ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μµμ ν™”ν•  λ•μ ν•µμ‹¬μ€ ν•μ΄νΌνλΌλ―Έν„°μ "**μµμ  κ°’**"μ΄ μ΅΄μ¬ν•λ” **λ²”μ„**λ¥Ό μ΅°κΈμ”© <ins>μ¤„μ—¬κ°„λ‹¤λ”</ins> κ²ƒμ…λ‹λ‹¤. λ²”μ„λ¥Ό μ΅°κΈμ”© μ¤„μ΄λ ¤λ©΄ μ°μ„  1. λ€λµμ μΈ λ²”μ„λ¥Ό μ„¤μ •ν•κ³  2. κ·Έ λ²”μ„μ—μ„ λ¬΄μ‘μ„λ΅ ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ κ³¨λΌλ‚Έ(μƒν”λ§) ν›„, 3. κ·Έ κ°’μΌλ΅ μ •ν™•λ„λ¥Ό ν‰κ°€ν•©λ‹λ‹¤. μ •ν™•λ„λ¥Ό μ μ‚΄ν”Όλ©΄μ„ μ΄ μ‘μ—…μ„ μ—¬λ¬ λ² λ°λ³µν•λ©° ν•μ΄νΌνλΌλ―Έν„°μ "μµμ  κ°’"μ„ λ²”μ„λ¥Ό μΆν€κ°€λ” κ²ƒμ…λ‹λ‹¤.

> π“ μ‹ κ²½λ§μ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”μ—μ„λ” **κ·Έλ¦¬λ“ μ„μΉ**(grid search)κ°™μ€ **κ·μΉ™μ μΈ** νƒμƒ‰λ³΄λ‹¤λ” **λ¬΄μ‘μ„λ΅ μƒν”λ§ν•΄** νƒμƒ‰ν•λ” νΈμ΄ **μΆ‹μ€** κ²°κ³Όλ¥Ό λ‚Έλ‹¤κ³  μ•λ ¤μ Έ μμµλ‹λ‹¤[^fn-hyper-parameter-optimization]. μ΄λ” μµμΆ… μ •ν™•λ„μ— λ―ΈμΉλ” μν–¥λ ¥μ΄ ν•μ΄νΌνλΌλ―Έν„°λ§λ‹¤ **λ‹¤λ¥΄κΈ°** λ•λ¬Έμ…λ‹λ‹¤.

ν•μ΄νΌνλΌλ―Έν„°μ λ²”μ„λ” '**λ€λµμ μΌλ΅**' μ§€μ •ν•λ” κ²ƒμ΄ ν¨κ³Όμ μ…λ‹λ‹¤. μ‹¤μ λ΅λ„ 0.001μ—μ„ 1,000 μ‚¬μ΄ $(10^{-3} \sim 10^{3})$μ™€ κ°™μ΄ **10μ κ±°λ“­μ κ³±** λ‹¨μ„λ΅ λ²”μ„λ¥Ό μ§€μ •ν•©λ‹λ‹¤. μ΄λ¥Ό **λ΅κ·Έ μ¤μΌ€μΌ**(log scale)λ΅ μ§€μ •ν•λ‹¤κ³  ν•©λ‹λ‹¤. ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μµμ ν™”ν•  λ•λ” λ”¥λ¬λ‹ ν•™μµμ—λ” **μ¤λ μ‹κ°„**(λ©°μΉ μ΄λ‚ λ‡ μ£Ό μ΄μƒ)μ΄ κ±Έλ¦°λ‹¤λ” μ μ„ κΈ°μ–µν•΄μ•Ό ν•©λ‹λ‹¤. λ”°λΌμ„ λ‚μ  λ“―ν• κ°’μ€ *μΌμ° ν¬κΈ°ν•λ”* κ² μΆ‹μµλ‹λ‹¤. κ·Έλμ„ ν•™μµμ„ μ„ν• μ—ν­μ„ *μ‘κ²* ν•μ—¬, 1ν ν‰κ°€μ— κ±Έλ¦¬λ” μ‹κ°„μ„ **λ‹¨μ¶•**ν•λ” κ²ƒμ΄ ν¨κ³Όμ μ…λ‹λ‹¤.

μ΄μƒμ΄ ν•μ΄νΌνλΌλ―Έν„°μ μµμ ν™”μ…λ‹λ‹¤. μ΄λ¥Ό μ •λ¦¬ν•λ©΄ λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

* 0λ‹¨κ³„
  * ν•μ΄νΌνλΌλ―Έν„° κ°’μ **λ²”μ„**λ¥Ό μ„¤μ •ν•©λ‹λ‹¤.
* 1λ‹¨κ³„
  * μ„¤μ •λ λ²”μ„μ—μ„ ν•μ΄νΌνλΌλ―Έν„°μ κ°’μ„ **λ¬΄μ‘μ„λ΅** μ¶”μ¶ν•©λ‹λ‹¤.
* 2λ‹¨κ³„
  * 1λ‹¨κ³„μ—μ„ μƒν”λ§ν• ν•μ΄νΌνλΌλ―Έν„° κ°’μ„ μ‚¬μ©ν•μ—¬ **ν•™μµ**ν•κ³ , **κ²€μ¦ λ°μ΄ν„°**λ΅ μ •ν™•λ„λ¥Ό ν‰κ°€ν•©λ‹λ‹¤(λ‹¨, μ—ν­μ€ μ‘κ² μ„¤μ •ν•©λ‹λ‹¤).
* 3λ‹¨κ³„
  * 1λ‹¨κ³„μ™€ 2λ‹¨κ³„λ¥Ό νΉμ • νμ(100ν λ“±) λ°λ³µν•λ©°, κ·Έ μ •ν™•λ„μ κ²°κ³Όλ¥Ό λ³΄κ³  ν•μ΄νΌνλΌλ―Έν„°μ λ²”μ„λ¥Ό **μΆν™λ‹λ‹¤**.

μ΄μƒμ„ λ°λ³µν•μ—¬ ν•μ΄νΌνλΌλ―Έν„°μ λ²”μ„λ¥Ό μΆν€κ°€κ³ , μ–΄λ μ •λ„ μΆμ•„μ§€λ©΄ κ·Έ μ••μ¶•ν• λ²”μ„μ—μ„ κ°’μ„ ν•λ‚ **κ³¨λΌλƒ…λ‹λ‹¤**. μ΄κ²ƒμ΄ ν•μ΄νΌνλΌλ―Έν„°λ¥Ό μµμ ν™”ν•λ” ν•λ‚μ λ°©λ²•μ…λ‹λ‹¤.

> π”† μ—¬κΈ°μ—μ„ μ„¤λ…ν• ν•μ΄νΌνλΌλ―Έν„° μµμ ν™” λ°©λ²•μ€ μ‹¤μ©μ μΈ λ°©λ²•μ…λ‹λ‹¤. λ” μ„Έλ ¨λ κΈ°λ²•μ„ μ›ν•λ‹¤λ©΄ **λ² μ΄μ¦ μµμ ν™”**(Bayesian optimization)[^fn-bayesian-optimization]λ¥Ό μ†κ°ν•  μ μκ² μµλ‹λ‹¤. λ² μ΄μ¦ μµμ ν™”λ” **λ² μ΄μ¦ μ •λ¦¬**(Bayes' theorem)λ¥Ό μ¤‘μ‹¬μΌλ΅ ν• μν•™ μ΄λ΅ μ„ κµ¬μ‚¬ν•μ—¬ λ” **μ—„λ°€ν•κ³  ν¨μ¨μ μΌλ΅** μµμ ν™”λ¥Ό μν–‰ν•©λ‹λ‹¤.

κ·Έλ¬λ©΄ ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”λ¥Ό ν•λ² μ μ©ν•΄λ³΄κ² μµλ‹λ‹¤. [Fig. 5.]μ—μ„λ” κ°€μ¤‘μΉ κ°μ† κ³„μλ¥Ό $10^{-8} \sim 10^{-3}$, ν•™μµλ¥ μ„ $10^{-6} \sim 10^{-1}$ λ²”μ„λ¶€ν„° μ‹μ‘ν–μµλ‹λ‹¤. κ²°κ³Όλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

<figure>
    <img src="/posts/study/machine learning/deep learning/images/learning_techniques_32.png"
         title="Comparison of accuracy between train and validation dataset within hyper parameter optimization"
         alt="Image of comparison of accuracy between train and validation dataset within hyper parameter optimization"
         class="img_center"
         style="width: 75%"/>
    <figcaption>ν•μ΄νΌνλΌλ―Έν„° μµμ ν™”λ¥Ό ν†µν• ν›λ ¨ λ°μ΄ν„°μ™€ κ²€μ¦ λ°μ΄ν„°μ μ •ν™•λ„ λΉ„κµ</figcaption>
</figure>

[Fig. 5.]μ—μ„λ” κ²€μ¦ λ°μ΄ν„°μ ν•™μµ μ¶”μ΄λ¥Ό μ •ν™•λ„κ°€ λ†’μ€ μμ„λ΅ "Best 6"κΉμ§€ λ‚μ—΄ν–μµλ‹λ‹¤. μ΄λ¥Ό λ°”νƒ•μΌλ΅ ν•μ΄νΌνλΌλ―Έν„°μ κ°’(ν•™μµλ¥ κ³Ό κ°€μ¤‘μΉ κ°μ† κ³„μ)μ„ μ‚΄ν΄λ³΄κ² μµλ‹λ‹¤. κ²°κ³Όλ” λ‹¤μκ³Ό κ°™μµλ‹λ‹¤.

```bash
Best 1 (0.89): lr:0.05567252269169351, weight decay:1.4486411822468745e-07
Best 2 (0.88): lr:0.025982059274246065, weight decay:2.399166472542664e-08
Best 3 (0.88): lr:0.03266666951643395, weight decay:0.00039864344919228147
Best 4 (0.88): lr:0.08622005359644884, weight decay:7.461699683307732e-08
Best 5 (0.87): lr:0.09742737935246511, weight decay:1.7644865261190753e-05
Best 6 (0.87): lr:0.04728076439891178, weight decay:3.874235915438321e-07
```

μ„ κ²°κ³Όλ¥Ό λ³΄λ©΄ ν•™μµμ΄ μ μ§„ν–‰λ  λ•μ ν•™μµλ¥ μ€ $0.01 \sim 0.1$, κ°€μ¤‘μΉ κ°μ† κ³„μλ” $10^{-8} \sim 10^{-4}$ μ •λ„λΌλ” κ²ƒμ„ μ• μ μμµλ‹λ‹¤. μ΄μ²λΌ ν•™μµ κ²°κ³Όκ°€ μΆ‹μ€ κ°’λ“¤μ λ²”μ„λ¥Ό κ΄€μ°°ν•κ³  λ²”μ„λ¥Ό μΆν€κ°‘λ‹λ‹¤. κ·Έλ° λ‹¤μ κ·Έ μ¶•μ†λ λ²”μ„μ—μ„ λ‘κ°™μ€ μ‘μ—…μ„ λ‹¤μ‹ λ°λ³µν•λ” κ²λ‹λ‹¤. μ΄λ ‡κ² μ μ ν• κ°’μ΄ μ„μΉν• λ²”μ„λ¥Ό μΆν€κ°€λ‹¤κ°€ νΉμ • λ‹¨κ³„μ—μ„ μµμΆ… ν•μ΄νΌνλΌλ―Έν„°μ κ°’μ„ ν•λ‚ μ„ νƒν•©λ‹λ‹¤.

μ§€κΈκΉμ§€ μ‹ κ²½λ§ ν•™μµμ— μ¤‘μ”ν• κΈ°μ  λ‡ κ°€μ§€μ— λ€ν• κΈ°μ΄μ™€ μ΄λ΅ , κµ¬ν„κΉμ§€ μ •λ¦¬ν•΄λ΄¤μµλ‹λ‹¤. λ‹¤μ postμ—μ„λ” **ν•©μ„±κ³± μ‹ κ²½λ§**(Convolutional Neural Network, CNN)μ— λ€ν•΄μ„ λ‹¤λ¤„λ³΄κ² μµλ‹λ‹¤.

## μ‹ κ²½λ§ ν•™μµ κ΄€λ ¨ κΈ°μ λ“¤ μ”μ•½
- λ§¤κ°λ³€μ κ°±μ‹  λ°©λ²•μ—λ” ν™•λ¥ μ  κ²½μ‚¬ ν•κ°•λ²•(SGD) μ™Έμ—λ„ λ¨λ©ν…€, AdaGrad, Adam λ“±μ΄ μλ‹¤.
- κ°€μ¤‘μΉ μ΄κΉƒκ°’μ„ μ •ν•λ” λ°©λ²•μ€ μ¬λ°”λ¥Έ ν•™μµμ„ ν•λ” λ° λ§¤μ° μ¤‘μ”ν•λ‹¤.
- κ°€μ¤‘μΉμ μ΄κΉƒκ°’μΌλ΅λ” "Xavier μ΄κΉƒκ°’"κ³Ό "He μ΄κΉƒκ°’"μ΄ ν¨κ³Όμ μ΄λ‹¤.
- λ°°μΉ μ •κ·ν™”λ¥Ό μ΄μ©ν•λ©΄ ν•™μµμ„ λΉ λ¥΄κ² μ§„ν–‰ν•  μ μμΌλ©°, μ΄κΉƒκ°’μ— μν–¥μ„ λ λ°›κ² λλ‹¤.
- μ¤λ²„ν”Όν…μ„ μ–µμ ν•λ” μ •κ·ν™” κΈ°μ λ΅λ” κ°€μ¤‘μΉ κ°μ†μ™€ λ“λ΅­μ•„μ›ƒμ΄ μλ‹¤.
- ν•μ΄νΌνλΌλ―Έν„° κ°’ νƒμƒ‰μ€ μµμ  κ°’μ΄ μ΅΄μ¬ν•  λ²•ν• λ²”μ„λ¥Ό μ μ°¨ μΆνλ©΄μ„ ν•λ” κ²ƒμ΄ ν¨κ³Όμ μ΄λ‹¤.

---

[^fn-hyper-parameter-optimization]: James Bergstra and Yoshua Bengio(2012): Random Search for Hyper-Parameter Optimization. Journal of Machine Learning Research 13, Feb(2012), 281-305.

[^fn-bayesian-optimization]: Jasper Snoek, Hugo Larochelle, and Ryan P. Adams(2012): Practical Bayesian Optimization of Machine Learning Algorithms. In F. Pereia, C. J. C. Burges, L. Bottou, & K. Q. Weinberger, eds. Advances in Neural Information Processing Systems 25. Curran Associates, Inc., 2951 - 2959.
