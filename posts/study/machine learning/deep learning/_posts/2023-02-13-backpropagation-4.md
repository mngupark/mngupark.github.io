---
layout: post
title: Backpropagation-4
category: deep learning
post-order: 14
---

ì´ì „ [post](https://gyuhub.github.io/posts/study/machine%20learning/deep%20learning/backpropation-3)ì—ì„œëŠ” í™œì„±í™” í•¨ìˆ˜ì˜ ì—­ì „íŒŒì— ëŒ€í•´ì„œ ë°°ì› ìŠµë‹ˆë‹¤. ì´ë²ˆ postì—ì„œëŠ” Affine ê³„ì¸µì— ëŒ€í•´ì„œ ì„¤ëª…í•´ë³´ê² ìŠµë‹ˆë‹¤.

---

# Affine ê³„ì¸µ

ì‹ ê²½ë§ì˜ ìˆœì „íŒŒì—ì„œëŠ” ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜ì˜ ì´í•©ì„ ê³„ì‚°í•˜ê¸° ë•Œë¬¸ì— **í–‰ë ¬ì˜ ê³±**ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ê·¸ ê³¼ì •ì—ì„œ Pythonì˜ numpy ëª¨ë“ˆì˜ np.dot() methodë¥¼ ì‚¬ìš©í–ˆì—ˆìŠµë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ë§¤ê°œë³€ìˆ˜(**W**)ì™€ ì…ë ¥ ì‹ í˜¸(**X**)ë¥¼ ê³±í•˜ê³  í¸í–¥(**B**)ì„ ë”í•´ì„œ ì´ë¥¼ í™œì„±í™” í•¨ìˆ˜ì˜ ì…ë ¥(**Y**)ìœ¼ë¡œ ì£¼ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  í™œì„±í™” í•¨ìˆ˜ì˜ ì…ë ¥ì„ "Y=np.dot(X,W)+B"ì™€ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ë•Œ í–‰ë ¬ê°„ì˜ ê³±ì…ˆì´ í–‰í•´ì§€ê¸° ë•Œë¬¸ì— í–‰ë ¬ê°„ì˜ ì°¨ì›ì„ ì˜ ë§ì¶°ì¤˜ì•¼ë§Œ í–ˆì—ˆìŠµë‹ˆë‹¤.

> ğŸ“‘ ì‹ ê²½ë§ì˜ ìˆœì „íŒŒì—ì„œ ìˆ˜í–‰í•˜ëŠ” í–‰ë ¬ì˜ ê³±ì„ ê¸°í•˜í•™ì—ì„œëŠ” **ì–´íŒŒì¸ ë³€í™˜**(affine transformation)ì´ë¼ê³  í•©ë‹ˆë‹¤. ì–´íŒŒì¸ ë³€í™˜ì— ëŒ€í•œ ìì„¸í•œ ì •ì˜ëŠ” [ì—¬ê¸°](https://en.wikipedia.org/wiki/Affine_transformation)ì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”.

Affine transformationì˜ ìˆœì „íŒŒì— ëŒ€í•œ ê³„ì‚°ì„ ê³„ì‚° ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ë³´ê² ìŠµë‹ˆë‹¤. í–‰ë ¬ê°„ì˜ ê³±ì…ˆì„ '**dot**'ë…¸ë“œë¡œ ë‚˜íƒ€ë‚´ê³ , ê° í–‰ë ¬ì˜ í˜•ìƒì„ numpyì˜ shape í•¨ìˆ˜ì™€ ê°™ì´ í‘œí˜„í•˜ê² ìŠµë‹ˆë‹¤.

<figure>
     <img src="/posts/study/machine learning/deep learning/images/backpropagation_19.jpg"
          title="Forward propagation of affine transformation"
          alt="Image of forward propagation of affine transformation"
          class="img_center"/>
     <figcaption>Affine ê³„ì¸µì˜ ìˆœì „íŒŒ</figcaption>
</figure>

[Fig. 1.]ì—ì„œ ê° ì…ë ¥ ì‹ í˜¸ë“¤ì€ í–‰ë ¬ì´ê¸°ì— **Bold**ë¡œ êµµê²Œ í‘œì‹œí•˜ê³  ê´„í˜¸ì•ˆì— ê·¸ í–‰ë ¬ì˜ í˜•ìƒì„ ì ì—ˆìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ê²½ìš°ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œ ì…ë ¥ ì‹ í˜¸ì˜ ì°¨ì›ì„ **n**, ì¶œë ¥ ì‹ í˜¸ì˜ ì°¨ì›ì„ **m**ìœ¼ë¡œ ê³„ì‚°í–ˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ í‘œí˜„í•œë‹¤ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$
\boldsymbol{X}_{1\times n}=\begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix},\ 
\boldsymbol{W}_{n\times m}=\begin{bmatrix}
w_{11} & w_{12} & \cdots & w_{1m} \\ 
w_{21} & w_{22} & \cdots & w_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
w_{n1} & w_{n2} & \cdots & w_{nm} \end{bmatrix}, \\
\boldsymbol{X}\cdot \boldsymbol{W}=\begin{bmatrix} \alpha_1 & \alpha_2 & \cdots & \alpha_m \end{bmatrix}\ 
(\alpha_i = \sum_{k=1}^n x_k \cdot w_{ki},\ i=1,2,\cdots,m) \label{dot_product_matrix} \tag{1}
$$

ì‹ $(\ref{dot_product_matrix})$ì—ì„œ ë‘ í–‰ë ¬ê°„ì˜ ë‚´ì ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¼ ì´ Affine ê³„ì¸µì— ëŒ€í•œ ì—­ì „íŒŒë¥¼ ê³„ì‚°í•´ë³´ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ì´ ë‚´ì ì˜ í¸ë¯¸ë¶„ì€ ì–´ë–»ê²Œ ê³„ì‚°í• ê¹Œìš”? í•˜ë‚˜ëŠ” í¬ê¸°ê°€ $1\times n$ì¸ ë²¡í„°ì´ê³  í•˜ë‚˜ëŠ” í¬ê¸°ê°€ $n\times m$ì¸ í–‰ë ¬ì¸ë° ë§ì…ë‹ˆë‹¤. ì´ëŠ” ì´ì „ì— ë°°ì› ì—ˆë˜ Chain ruleì„ ì´ìš©í•´ì„œ ì¦ëª…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œ ìš°ì„  ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ í•˜ë‚˜ì”© ê³„ì‚°í•´ë³´ê² ìŠµë‹ˆë‹¤.

## ë§ì…ˆ ë…¸ë“œ

ë¨¼ì € $\frac{\partial{L}}{\partial{Y}}$ê°€ ì—­ì „íŒŒì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ë’¤ ë§ì…ˆ ë…¸ë“œë¥¼ ì§€ë‚˜ì¹˜ê²Œ ë©ë‹ˆë‹¤. ë§ì…ˆ ë…¸ë“œì˜ ì—­ì „íŒŒëŠ” ìƒë¥˜ì˜ ì‹ í˜¸ë¥¼ ê·¸ëŒ€ë¡œ(1ì„ ê³±í•´ì„œ) í•˜ë¥˜ë¡œ í˜ë¦½ë‹ˆë‹¤. ë”°ë¼ì„œ ì•„ë˜ì˜ ê³„ì‚° ê·¸ë˜í”„ì™€ ê°™ì´ ë‚´ì  ë…¸ë“œì˜ ì…ë ¥ìœ¼ë¡œ ê·¸ëŒ€ë¡œ í˜ëŸ¬ê°€ê²Œ ë©ë‹ˆë‹¤.

<figure>
     <img src="/posts/study/machine learning/deep learning/images/backpropagation_20.jpg"
          title="Backpropagation of affine transformation"
          alt="Image of backpropagation of affine transformation"
          class="img_center"/>
     <figcaption>Affine ê³„ì¸µì˜ ë§ì…ˆ ë…¸ë“œì˜ ì—­ì „íŒŒ</figcaption>
</figure>

## ë‚´ì  ë…¸ë“œ

ë¨¼ì € $\frac{\partial{L}}{\partial{\boldsymbol{X}}}$ì— ëŒ€í•œ ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$
\begin{matrix}
\frac{\partial{\boldsymbol{X}\cdot \boldsymbol{W}}}{\partial{\boldsymbol{X}}}
&=&\frac{\partial{\begin{bmatrix} \alpha_1 & \alpha_2 & \cdots & \alpha_m \end{bmatrix}}}
{\partial{\begin{bmatrix} x_1 & x_2 & \cdots & x_n \end{bmatrix}}} \\
&=& \begin{bmatrix}
\frac{\partial{\alpha_1}}{\partial{x_1}} & \frac{\partial{\alpha_1}}{\partial{x_2}} & \cdots & \frac{\partial{\alpha_1}}{\partial{x_n}} \\
\frac{\partial{\alpha_2}}{\partial{x_1}} & \frac{\partial{\alpha_2}}{\partial{x_2}} & \cdots & \frac{\partial{\alpha_2}}{\partial{x_n}} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial{\alpha_m}}{\partial{x_1}} & \frac{\partial{\alpha_m}}{\partial{x_2}} & \cdots & \frac{\partial{\alpha_m}}{\partial{x_n}}
\end{bmatrix}
&=& \begin{bmatrix}
w_{11} & w_{21} & \cdots & w_{n1} \\
w_{12} & w_{22} & \cdots & w_{n2} \\
\vdots & \vdots & \ddots & \vdots \\
w_{1m} & w_{2m} & \cdots & w_{nm}
\end{bmatrix}\ (\frac{\partial{\alpha_i}}{\partial{x_j}}=w_{ji}) \\
&=& \boldsymbol{W}^T
\end{matrix} \\
\therefore \frac{\partial{L}}{\partial{\boldsymbol{X}}}=\frac{\partial{L}}{\partial{\boldsymbol{Y}}}\frac{\partial{\boldsymbol{Y}}}{\partial{\boldsymbol{X}}}
=\frac{\partial{L}}{\partial{\boldsymbol{Y}}}\boldsymbol{W}^T \label{L_X} \tag{2}
$$

$\frac{\partial{L}}{\partial{\boldsymbol{W}}}$ì— ëŒ€í•œ ìˆ˜ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.  

$$
\begin{matrix}
\frac{\partial{\boldsymbol{X}\cdot \boldsymbol{W}}}{\partial{\boldsymbol{W}}}
&=&\frac{\partial{\begin{bmatrix} \alpha_1 & \alpha_2 & \cdots & \alpha_m \end{bmatrix}}}
{\partial{\begin{bmatrix}
w_{11} & w_{12} & \cdots & w_{1m} \\
w_{21} & w_{22} & \cdots & w_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
w_{n1} & w_{n2} & \cdots & w_{nm} \end{bmatrix}}}
\end{matrix} \label{L_W} \tag{3}
$$

ì‹ $(\ref{L_X})$ì—ì„œëŠ” $\frac{\partial{L}}{\partial{\boldsymbol{X}}}$ë¥¼ ê³„ì‚°í•˜ë‹ˆ 2ì°¨ì› í–‰ë ¬ì´ ë‚˜ì™”ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì‹ $(\ref{L_W})$ì—ì„œì˜ $\frac{\partial{L}}{\partial{\boldsymbol{W}}}$ë¥¼ ê³„ì‚°í•˜ë©´ 3ì°¨ì› í…ì„œê°€ ë‚˜ì˜µë‹ˆë‹¤. ì´ë¥¼ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•˜ê¸° í˜ë“¤ê¸°ì— ë‹¤ë¥¸ ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ ì¦ëª…í•˜ê² ìŠµë‹ˆë‹¤. ë°”ë¡œ **Chain rule**ì„ ì‚¬ìš©í•´ì„œ ì¦ëª…í•˜ê² ìŠµë‹ˆë‹¤.

$$
\begin{matrix}
\frac{\partial{L}}{\partial{\boldsymbol{W}}}&=&\frac{\partial{L}}{\partial{\boldsymbol{Y}}}\frac{\boldsymbol{Y}}{\partial{\boldsymbol{W}}} \\
&=&\begin{bmatrix}
\frac{\partial{L}}{\partial{w_{11}}} & \frac{\partial{L}}{\partial{w_{12}}} & \cdots & \frac{\partial{L}}{\partial{w_{1m}}} \\
\frac{\partial{L}}{\partial{w_{21}}} & \frac{\partial{L}}{\partial{w_{22}}} & \cdots & \frac{\partial{L}}{\partial{w_{2m}}} \\
\vdots & \vdots & \cdots & \vdots \\
\frac{\partial{L}}{\partial{w_{n1}}} & \frac{\partial{L}}{\partial{w_{n2}}} & \cdots & \frac{\partial{L}}{\partial{w_{nm}}} \end{bmatrix}, \\
\frac{\partial{L}}{\partial{w_{ij}}}&=&\sum_{k=1}^m \frac{\partial{L}}{\partial{y_{k}}}\frac{\partial{y_k}}{\partial{w_{ij}}} \\
&=&\frac{\partial{L}}{\partial{\boldsymbol{Y}}}\frac{\boldsymbol{Y}}{\partial{w_{ij}}}, \\
\frac{\partial{y_k}}{\partial{w_{ij}}}&=&\begin{cases} x_i\ (k=j) \\ 0\ (k\neq j) \end{cases}, \\
\frac{\partial{L}}{\partial{w_{ij}}}&=&\sum_{k=1}^m \frac{\partial{L}}{\partial{y_{k}}}\frac{\partial{y_k}}{\partial{w_{ij}}}
&=&\sum_{k=1}^m \frac{\partial{L}}{\partial{y_{k}}}x_i \\
&=&x_i \frac{\partial{L}}{\partial{y_j}}, \\
\frac{\partial{L}}{\partial{\boldsymbol{W}}}&=&
\begin{bmatrix}
x_1 \frac{\partial{L}}{\partial{y_1}} & x_1 \frac{\partial{L}}{\partial{y_2}} & \cdots x_1 \frac{\partial{L}}{\partial{y_m}} \\
x_2 \frac{\partial{L}}{\partial{y_1}} & x_2 \frac{\partial{L}}{\partial{y_2}} & \cdots x_2 \frac{\partial{L}}{\partial{y_m}} \\
\vdots & \vdots & \cdots & \vdots \\
x_n \frac{\partial{L}}{\partial{y_1}} & x_n \frac{\partial{L}}{\partial{y_2}} & \cdots x_n \frac{\partial{L}}{\partial{y_m}} \end{bmatrix} \\
&=& \boldsymbol{X}^T\frac{\partial{L}}{\partial{\boldsymbol{Y}}}
\end{matrix} \\
\therefore \frac{\partial{L}}{\partial{\boldsymbol{W}}}=\frac{\partial{L}}{\partial{\boldsymbol{Y}}}\frac{\partial{\boldsymbol{Y}}}{\partial{\boldsymbol{W}}}
=\boldsymbol{X}^T\frac{\partial{L}}{\partial{\boldsymbol{Y}}} \tag{4}
$$

ì¦ëª… ê³¼ì •ì´ ë§ì´ ê¸¸ì—ˆëŠ”ë°, ìš”ì•½í•˜ë©´ ì•„ë˜ ìˆ˜ì‹ê³¼ ê°™ìŠµë‹ˆë‹¤.

$$
\begin{matrix}
\frac{\partial{L}}{\partial{\boldsymbol{X}}}&=&\frac{\partial{L}}{\partial{\boldsymbol{Y}}}\boldsymbol{W}^T \\
\frac{\partial{L}}{\partial{\boldsymbol{W}}}&=&\boldsymbol{X}^T\frac{\partial{L}}{\partial{\boldsymbol{Y}}} \end{matrix} \label{affine_backpropagation} \tag{5}
$$

ì‹ $(\ref{affine_backpropagation})$ë¥¼ ê³„ì‚° ê·¸ë˜í”„ë¡œ í‘œí˜„í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

<figure>
     <img src="/posts/study/machine learning/deep learning/images/backpropagation_21.jpg"
          title="Backpropagation of affine transformation"
          alt="Image of backpropagation of affine transformation"
          class="img_center"/>
     <figcaption>Affine ê³„ì¸µì˜ ì—­ì „íŒŒ</figcaption>
</figure>

---

# ë°°ì¹˜ìš© Affine ê³„ì¸µ

ì§€ê¸ˆê¹Œì§€ ì„¤ëª…í•œ Affine ê³„ì¸µì€ ì…ë ¥ ë°ì´í„°ë¡œ $\boldsymbol{X}$ í•˜ë‚˜ë§Œì„ ê³ ë ¤í•œ ê²ƒì´ì—ˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ë°ì´í„° $\boldsymbol{N}$ê°œë¥¼ ë¬¶ì–´ ìˆœì „íŒŒí•˜ëŠ” ê²½ìš°ì¸ **ë°°ì¹˜ìš© Affine ê³„ì¸µ**ì„ ì„¤ëª…í•´ë³´ê² ìŠµë‹ˆë‹¤. ê³„ì‚° ê·¸ë˜í”„ë¡œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

<figure>
     <img src="/posts/study/machine learning/deep learning/images/backpropagation_22.jpg"
          title="Backpropagation of batch affine transformation"
          alt="Image of backpropagation of batch affine transformation"
          class="img_center"/>
     <figcaption>ë°°ì¹˜ìš© Affine ê³„ì¸µì˜ ì—­ì „íŒŒ</figcaption>
</figure>

[Fig. 4.]ì—ì„œ ê¸°ì¡´ê³¼ ë‹¬ë¼ì§„ ë¶€ë¶„ì€ ì…ë ¥ì¸ $\boldsymbol{X}$ì˜ í˜•ìƒì´ $(n,)$ì—ì„œ $(N,n)$ìœ¼ë¡œ ë°”ë€ ê²ƒ ë¿ì…ë‹ˆë‹¤. ì´ì— ë”°ë¼ì„œ ê°€ì¤‘ì¹˜ë‚˜ í¸í–¥ ë§¤ê°œë³€ìˆ˜, ì¶œë ¥ê³¼ ì—­ì „íŒŒ ë“±ì´ í–‰ë ¬ì˜ í˜•ìƒì— ë§ê²Œ í¬ê¸°ê°€ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤. í¬ê¸°ê°€ ë°”ë€Œì—ˆì§€ë§Œ ì´ì „ê³¼ ë¹„ìŠ·í•˜ê²Œ ì¦ëª…í•˜ëŠ” ê³¼ì •ì„ í†µí•´ì„œ ì‹ $(\ref{affine_backpropagation})$ì™€ ê°™ì€ ì—­ì „íŒŒë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ì´ì— ëŒ€í•œ ì¦ëª… ê³¼ì •ì€ ìƒëµí•˜ê² ìŠµë‹ˆë‹¤. ğŸ˜…

ì£¼ì˜í•´ì•¼í•  ì ì€ ì´ë¥¼ Pythonìœ¼ë¡œ êµ¬í˜„í•  ë•Œ í¸í–¥ì„ ë”í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ìˆœì „íŒŒ ë•Œì˜ í¸í–¥ ë§ì…ˆì€ $\boldsymbol{X}\cdot\boldsymbol{W}$ì— ëŒ€í•œ í¸í–¥ì´ **ê° ë°ì´í„°**ì— ë”í•´ì§‘ë‹ˆë‹¤. ì¦‰, í¸í–¥ì€ $\boldsymbol{N}$ê°œì˜ ë°ì´í„° ê°ê°ì— ë‹¤ ë”í•´ì§‘ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python
>>> import numpy as np
>>> X_dot_W = np.array([[1, 2, 3],[6, 8, 10]])
>>> B = np.array([1, -1, 5])
>>> X_dot_W
array([[ 1,  2,  3],
       [ 6,  8, 10]]) 
>>> X_dot_W + B
array([[ 2,  1,  8],
       [ 7,  7, 15]])
```

ìˆœì „íŒŒì˜ í¸í–¥ ë§ì…ˆì€ ê°ê°ì˜ ë°ì´í„°(1ë²ˆì§¸ ë°ì´í„°, 2ë²ˆì§¸ ë°ì´í„°, $\cdots$)ì— ë”í•´ì§‘ë‹ˆë‹¤. ê·¸ë˜ì„œ **ì—­ì „íŒŒ** ë•ŒëŠ” ê° ë°ì´í„°ì˜ ì—­ì „íŒŒ ê°’ì´ **í¸í–¥ì˜ ì›ì†Œ**ì— ëª¨ì—¬ì•¼ í•©ë‹ˆë‹¤. ì½”ë“œë¡œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python
>>> import numpy as np
>>> dY = np.array([[7, 5, 3], [2, 4, 8]])
>>> dY
array([[7, 5, 3],
       [2, 4, 8]])
>>> dB = np.sum(dY, axis=0)
>>> dB
array([ 9,  9, 11])
```

í¸í–¥ì˜ ì—­ì „íŒŒëŠ” ê·¸ $\boldsymbol{N}$ê°œì˜ ë°ì´í„°ì— ëŒ€í•œ ë¯¸ë¶„ì„ ë°ì´í„°ë§ˆë‹¤ ë”í•´ì„œ êµ¬í•©ë‹ˆë‹¤. ê·¸ëŸ¼ ì´ì œ Pythonì„ ì´ìš©í•´ì„œ Affine ê³„ì¸µì„ êµ¬í˜„í•´ë³´ê² ìŠµë‹ˆë‹¤.
```python
class AffineLayer:
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.original_x_shape = None
        self.dW = None
        self.db = None

    def forward(self, x):
        self.original_x_shape = x.shape # for tensor input
        x = x.reshape(x.shape[0], -1)
        self.x = x
        return (np.dot(self.x, self.W) + self.b)

    def backward(self, dout):
        dx = np.dot(dout, self.W.T)
        self.dW = np.dot(self.x.T, dout)
        self.db = np.sum(dout, axis=0)
        dx = dx.reshape(*self.original_x_shape) # for tensor input
        return dx
```